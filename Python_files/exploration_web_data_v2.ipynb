{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV or paste raw data\n",
    "df = pd.read_csv(\"/Users/jon/Desktop/Ironhack/Unit 4 - Statistics & Probability/Project-Statistics/Databases/cleaned/df_cleaned_web_data_vfinal.txt\", parse_dates=[\"date_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCULATION OF AVERAGE TIMINGS BY STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  process_step  time_spent\n",
      "0        start   58.696367\n",
      "1       step_1   60.524441\n",
      "2       step_2   92.450280\n",
      "3       step_3  132.116471\n"
     ]
    }
   ],
   "source": [
    "# Group by 'process_step' and calculate the average time\n",
    "avg_time_per_step = df.groupby(\"process_step\")[\"time_spent\"].mean().reset_index()\n",
    "\n",
    "# Sort by a logical step order if needed\n",
    "step_order = [\"start\", \"step_1\", \"step_2\", \"step_3\", \"confirm\"]\n",
    "avg_time_per_step[\"step_order\"] = avg_time_per_step[\"process_step\"].apply(lambda x: step_order.index(x) if x in step_order else -1)\n",
    "avg_time_per_step = avg_time_per_step.sort_values(\"step_order\").drop(columns=\"step_order\")\n",
    "\n",
    "# Display result\n",
    "print(avg_time_per_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNNEL OF CONVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funnel Conversion (% of users from 'start'):\n",
      "\n",
      "              num_visits  conversion_rate\n",
      "process_step                             \n",
      "start             130490       100.000000\n",
      "step_1            110012        84.306843\n",
      "step_2             99790        76.473293\n",
      "step_3             88738        68.003678\n"
     ]
    }
   ],
   "source": [
    "# Sort actions chronologically per visit\n",
    "df = df.sort_values(by=[\"visit_id\", \"date_time\"])\n",
    "\n",
    "# Remove duplicate steps per visit (to avoid loops/skips being counted multiple times)\n",
    "df_unique_steps = df.drop_duplicates(subset=[\"visit_id\", \"process_step\"])\n",
    "\n",
    "# Define the correct step order for the funnel\n",
    "step_order = [\"start\", \"step_1\", \"step_2\", \"step_3\"]\n",
    "\n",
    "# Count how many unique visits reached each step\n",
    "step_counts = df_unique_steps.groupby(\"process_step\")[\"visit_id\"].nunique().reindex(step_order, fill_value=0)\n",
    "\n",
    "# Calculate funnel conversion from the first step\n",
    "funnel = step_counts.to_frame(name=\"num_visits\")\n",
    "funnel[\"conversion_rate\"] = funnel[\"num_visits\"] / funnel[\"num_visits\"].iloc[0] * 100  # % from start\n",
    "\n",
    "# Display results\n",
    "print(\"Funnel Conversion (% of users from 'start'):\\n\")\n",
    "print(funnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg Timing per Step, Fastest Group, and Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge both databases i'll be using\n",
    "\n",
    "# Load the web steps data with date_time parsed as datetime\n",
    "df_web = pd.read_csv(\n",
    "    \"/Users/jon/Desktop/Ironhack/Unit 4 - Statistics & Probability/Project-Statistics/Databases/cleaned/df_cleaned_web_data_vfinal.txt\",\n",
    "    parse_dates=[\"date_time\"]\n",
    ")\n",
    "\n",
    "# Load the experiment clients data\n",
    "df_exp = pd.read_csv(\n",
    "    \"/Users/jon/Desktop/Ironhack/Unit 4 - Statistics & Probability/Project-Statistics/Databases/cleaned/df_cleaned_experiment_clients_data.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   client_id             visitor_id                     visit_id process_step  \\\n",
      "0    7338123  612065484_94198474375  100019538_17884295066_43909        start   \n",
      "1    7338123  612065484_94198474375  100019538_17884295066_43909       step_1   \n",
      "2    7338123  612065484_94198474375  100019538_17884295066_43909       step_2   \n",
      "3    7338123  612065484_94198474375  100019538_17884295066_43909       step_1   \n",
      "4    7338123  612065484_94198474375  100019538_17884295066_43909       step_1   \n",
      "\n",
      "            date_time           next_time  time_spent Variation  \n",
      "0 2017-04-09 16:20:56 2017-04-09 16:21:12        16.0      Test  \n",
      "1 2017-04-09 16:21:12 2017-04-09 16:21:21         9.0      Test  \n",
      "2 2017-04-09 16:21:21 2017-04-09 16:21:35        14.0      Test  \n",
      "3 2017-04-09 16:21:35 2017-04-09 16:21:41         6.0      Test  \n",
      "4 2017-04-09 16:21:41 2017-04-09 16:21:45         4.0      Test  \n"
     ]
    }
   ],
   "source": [
    "# Merge experiment variation info into web steps data\n",
    "df_merged = df_web.merge(df_exp, on=\"client_id\", how=\"inner\")\n",
    "\n",
    "# Sort by visit_id and date_time to ensure correct order\n",
    "df_merged = df_merged.sort_values(by=[\"visit_id\", \"date_time\"])\n",
    "\n",
    "# Calculate next timestamp per visit (for duration calculation)\n",
    "df_merged[\"next_time\"] = df_merged.groupby(\"visit_id\")[\"date_time\"].shift(-1)\n",
    "\n",
    "# Calculate time spent in seconds on each step\n",
    "df_merged[\"time_spent\"] = (df_merged[\"next_time\"] - df_merged[\"date_time\"]).dt.total_seconds()\n",
    "\n",
    "# Remove rows where next_time is null (last step in visit)\n",
    "df_valid = df_merged.dropna(subset=[\"time_spent\"]).copy()\n",
    "\n",
    "# Optional: show first rows for verification\n",
    "print(df_valid.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Average Timings + T-tests per Step & Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  process_step  avg_time_test  avg_time_control  test_n  control_n  \\\n",
      "0        start      58.438816         65.903188   41359      31308   \n",
      "1       step_1      61.021054         50.635360   32631      23903   \n",
      "2       step_2      87.922946         91.502835   27046      22047   \n",
      "3       step_3     222.037115        176.775640    4769       5197   \n",
      "\n",
      "  faster_group       p_value significant  \n",
      "0         Test  1.958198e-04         Yes  \n",
      "1      Control  7.395664e-16         Yes  \n",
      "2         Test  1.684758e-02         Yes  \n",
      "3      Control  2.659241e-09         Yes  \n"
     ]
    }
   ],
   "source": [
    "# Group by step and variation to calculate mean and count\n",
    "grouped = df_valid.groupby([\"process_step\", \"Variation\"])[\"time_spent\"]\n",
    "avg_time = grouped.mean().unstack()       # avg time per step per group\n",
    "counts = grouped.count().unstack()        # counts per step per group\n",
    "\n",
    "# List of unique process steps\n",
    "steps = df_valid[\"process_step\"].unique()\n",
    "\n",
    "# Prepare results list\n",
    "results = []\n",
    "\n",
    "for step in steps:\n",
    "    # Extract time_spent for Test and Control groups for this step\n",
    "    test_times = df_valid[(df_valid[\"process_step\"] == step) & (df_valid[\"Variation\"] == \"Test\")][\"time_spent\"]\n",
    "    control_times = df_valid[(df_valid[\"process_step\"] == step) & (df_valid[\"Variation\"] == \"Control\")][\"time_spent\"]\n",
    "    \n",
    "    # Perform t-test if we have enough data (>1 in each group)\n",
    "    if len(test_times) > 1 and len(control_times) > 1:\n",
    "        stat, pval = ttest_ind(test_times, control_times, equal_var=False)  # Welch's t-test\n",
    "    else:\n",
    "        pval = np.nan  # Not enough data\n",
    "    \n",
    "    # Identify faster group\n",
    "    faster_group = None\n",
    "    if step in avg_time.index:\n",
    "        if avg_time.loc[step, \"Test\"] < avg_time.loc[step, \"Control\"]:\n",
    "            faster_group = \"Test\"\n",
    "        elif avg_time.loc[step, \"Control\"] < avg_time.loc[step, \"Test\"]:\n",
    "            faster_group = \"Control\"\n",
    "    \n",
    "    results.append({\n",
    "        \"process_step\": step,\n",
    "        \"avg_time_test\": avg_time.loc[step, \"Test\"] if \"Test\" in avg_time.columns else np.nan,\n",
    "        \"avg_time_control\": avg_time.loc[step, \"Control\"] if \"Control\" in avg_time.columns else np.nan,\n",
    "        \"test_n\": counts.loc[step, \"Test\"] if \"Test\" in counts.columns else 0,\n",
    "        \"control_n\": counts.loc[step, \"Control\"] if \"Control\" in counts.columns else 0,\n",
    "        \"faster_group\": faster_group,\n",
    "        \"p_value\": pval\n",
    "    })\n",
    "\n",
    "# Convert results list to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Optional: sort steps in natural order if you want\n",
    "step_order = ['start', 'step_1', 'step_2', 'step_3', 'confirm']\n",
    "results_df[\"step_order\"] = results_df[\"process_step\"].apply(lambda x: step_order.index(x) if x in step_order else 99)\n",
    "results_df = results_df.sort_values(\"step_order\").drop(columns=\"step_order\")\n",
    "results_df[\"significant\"] = results_df[\"p_value\"].apply(lambda p: \"Yes\" if p < 0.05 else \"No\")\n",
    "\n",
    "# Show results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Total Average Timings + T-tests  & Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  process_step  avg_time_test  avg_time_control  test_n  control_n  \\\n",
      "0   total_time     285.314518        276.650628   27496      22446   \n",
      "\n",
      "  faster_group   p_value significant  \n",
      "0      Control  0.074391          No  \n"
     ]
    }
   ],
   "source": [
    "# Sum time_spent per visit and variation\n",
    "total_time_per_visit = df_valid.groupby([\"visit_id\", \"Variation\"])[\"time_spent\"].sum().reset_index()\n",
    "\n",
    "# Average total time per group\n",
    "avg_total_time = total_time_per_visit.groupby(\"Variation\")[\"time_spent\"].mean()\n",
    "\n",
    "# Counts per group (number of visits)\n",
    "counts = total_time_per_visit[\"Variation\"].value_counts()\n",
    "\n",
    "# Extract total times per group for t-test\n",
    "test_times = total_time_per_visit[total_time_per_visit[\"Variation\"] == \"Test\"][\"time_spent\"]\n",
    "control_times = total_time_per_visit[total_time_per_visit[\"Variation\"] == \"Control\"][\"time_spent\"]\n",
    "\n",
    "# Run Welch's t-test\n",
    "stat, p_value = ttest_ind(test_times, control_times, equal_var=False)\n",
    "\n",
    "# Determine faster group\n",
    "if avg_total_time.get(\"Test\", np.nan) < avg_total_time.get(\"Control\", np.nan):\n",
    "    faster_group = \"Test\"\n",
    "else:\n",
    "    faster_group = \"Control\"\n",
    "\n",
    "# Create a summary DataFrame with the same style as your example\n",
    "summary_total_time = pd.DataFrame({\n",
    "    \"process_step\": [\"total_time\"],\n",
    "    \"avg_time_test\": [avg_total_time.get(\"Test\", np.nan)],\n",
    "    \"avg_time_control\": [avg_total_time.get(\"Control\", np.nan)],\n",
    "    \"test_n\": [counts.get(\"Test\", 0)],\n",
    "    \"control_n\": [counts.get(\"Control\", 0)],\n",
    "    \"faster_group\": [faster_group],\n",
    "    \"p_value\": [p_value],\n",
    "    \"significant\": [\"Yes\" if p_value < 0.05 else \"No\"]\n",
    "})\n",
    "\n",
    "print(summary_total_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
